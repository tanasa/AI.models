{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0dfac36-a684-4c13-9c3f-e3f0cbb73cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.baeldung.com/cs/pytorch-generative-adversarial-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce750d2-a73b-482a-80e3-df6a3d0aff6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "We train two competing and cooperating neural networks called generator (G ) and discriminator or critic (D). \n",
      "First, G takes random values from a multivariate Gaussian and produces a synthetic image. After that, \n",
      "D learns to distinguish between the real and the generated images. \n",
      "The goal of G is to produce a realistic sample that can fool D, whereas D has the opposite goal: \n",
      "to learn to differentiate actual from fake images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(''' \n",
    "We train two competing and cooperating neural networks called generator (G ) and discriminator or critic (D). \n",
    "First, G takes random values from a multivariate Gaussian and produces a synthetic image. After that, \n",
    "D learns to distinguish between the real and the generated images. \n",
    "The goal of G is to produce a realistic sample that can fool D, whereas D has the opposite goal: \n",
    "to learn to differentiate actual from fake images.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc7e5a3a-7ac9-4a3d-a25d-13e3e981d121",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 22:28:05.073504: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-01 22:28:05.083383: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733120885.094493   49632 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733120885.097884   49632 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-01 22:28:05.109682: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# For image transforms\n",
    "import torchvision.transforms as transforms\n",
    "# For Pytorch methods\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# For Optimizer\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "# For DATA SET\n",
    "from torchvision import datasets, transforms \n",
    "# FOR DATA LOADER\n",
    "from torch.utils.data import DataLoader\n",
    "# FOR TENSOR BOARD VISUALIZATION\n",
    "from torch.utils.tensorboard import SummaryWriter # to print to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b026a5cd-a2b6-4337-8b62-8aefe9222ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    zDim = 100            # Latent space dimension\n",
    "    imageDim = 28 * 28    # Flattened size of MNIST images\n",
    "    batchSize = 64        # Batch size\n",
    "    # numEpochs = 50      # Number of epochs\n",
    "    numEpochs = 10  \n",
    "    lr = 0.0002           # Learning rate\n",
    "    logStep = 100         # Logging frequency\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6630a0e7-73d6-4cab-8fd8-a585fd74c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "myTransforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,)),\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a249fcd9-cc54-4b0d-bd5e-2f7d97554169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST is a handwritten digit database with each digit as a 28X28 monochrome images\n",
    "# Each image sample is flattened to a 784-dimensional vector (imageDim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e8d5b1e-b7e5-44ec-8436-06f5bf7e36dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(root=\"/home/bogdan/Desktop/PyTorch/MNIST/\",\n",
    "                         transform=myTransforms,\n",
    "                         download=True)\n",
    "loader = DataLoader(dataset,\n",
    "                    batch_size=Config.batchSize,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e61ae6ff-f9c8-460a-b6b1-b40ea650acf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We used a sequential neural network to implement the generator block. \n",
      "It comprises an input layer with the Leaky ReLu() activation function, \n",
      "followed by a single hidden layer with the tanh() activation function.\n"
     ]
    }
   ],
   "source": [
    "print('''We used a sequential neural network to implement the generator block. \n",
    "It comprises an input layer with the Leaky ReLu() activation function, \n",
    "followed by a single hidden layer with the tanh() activation function.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f6b3488-0932-4fd4-8165-52379f822d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, zDim, imgDim, hiddenDim=512, leakySlope=0.01):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(zDim, hiddenDim),\n",
    "            nn.LeakyReLU(leakySlope),\n",
    "            nn.Linear(hiddenDim, imgDim),\n",
    "            nn.Tanh(),  # Output normalized to [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee92370d-1d08-4ec0-a3b0-24b4d5163e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The discriminator network is similar to the generator. \n",
      "However, its output layer gives a single output \n",
      "(1 for real data and 0 for synthetic data)\n"
     ]
    }
   ],
   "source": [
    "print('''The discriminator network is similar to the generator. \n",
    "However, its output layer gives a single output \n",
    "(1 for real data and 0 for synthetic data)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cade2a0-f0cd-4bfb-b503-c62ad7e47ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, inFeatures, hiddenDim=512, leakySlope=0.01):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(inFeatures, hiddenDim),\n",
    "            nn.LeakyReLU(leakySlope),\n",
    "            nn.Linear(hiddenDim, 1),\n",
    "            nn.Sigmoid(),  # Output probability\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "391c8654-7f28-42ff-baa4-fdc645ae5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first create the generator and discriminator objects. \n",
    "# Then, we sample the standard Gaussian noise to generate random samples. \n",
    "# Following this step, we normalize the monochromatic image map (784-dimensional vector) \n",
    "# and convert it to a tensor for processing.\n",
    "\n",
    "# discriminator = Discriminator(Config.imageDim).to(Config.device)\n",
    "# generator = Generator(Config.zDim,\n",
    "#                       Config.imageDim).to(Config.device)\n",
    "\n",
    "# Fixed Noise\n",
    "fixedNoise = torch.randn((Config.batchSize,\n",
    "                              Config.zDim)).to(Config.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4963747-361c-4cc2-a491-c4ddde26211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the output image dimension is 28x28 = 784\n",
    "imgDim = 28 * 28  # Output image dimension for MNIST dataset\n",
    "# Model Initialization\n",
    "gen = Generator(Config.zDim, Config.imageDim).to(Config.device)\n",
    "disc = Discriminator(Config.imageDim).to(Config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e44cb2c-6489-464a-8748-8d21f20f5858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization operation reduces each channelâ€™s pixel value with its mean and divides the result with its standard deviation:\n",
    "# image = image - mu / sigma\n",
    "# So, transforms.Normalize((0.5,), (0.5,)) converts MNIST image pixel values from the range [0, 1] to [-1, 1]. \n",
    "# Hence, this matches the tanh() output of G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c5a9259-5a17-4774-9372-53655c07b931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting Optimizers\n",
      "Setting the binary cross entropy (BCE) as loss function\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSetting Optimizers\")\n",
    "\n",
    "# Optimizers\n",
    "optGen = optim.Adam(gen.parameters(), lr=Config.lr, betas=(0.5, 0.999))\n",
    "optDisc = optim.Adam(disc.parameters(), lr=Config.lr, betas=(0.5, 0.999))\n",
    "\n",
    "print(f\"Setting the binary cross entropy (BCE) as loss function\")\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "245da5d0-61cc-4119-8a0a-8f04d607fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "writerFake = SummaryWriter(f\"logs/fake\")\n",
    "writerReal = SummaryWriter(f\"logs/real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2c1a633-1e71-441a-bd15-3cdef4355c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the training step: we get a random batch of real images from our dataset in each epoch. \n",
      "Then, we train our discriminator by showing it synthetic and real images. \n",
      "Once thatâ€™s over, we train the generator, keeping the discriminator intact. \n",
      "Finally, we come to the training step. We get a random batch of real images from our dataset in each epoch. \n",
      "Then, we train our discriminator by showing it synthetic and real images. \n",
      "Once thatâ€™s over, we train the generator, keeping the discriminator intact.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('''In the training step: we get a random batch of real images from our dataset in each epoch. \n",
    "Then, we train our discriminator by showing it synthetic and real images. \n",
    "Once thatâ€™s over, we train the generator, keeping the discriminator intact. \n",
    "Finally, we come to the training step. We get a random batch of real images from our dataset in each epoch. \n",
    "Then, we train our discriminator by showing it synthetic and real images. \n",
    "Once thatâ€™s over, we train the generator, keeping the discriminator intact.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bff7bbc-ec8f-4ec4-9368-84a4991786ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Function\n",
    "def prepareVisualization(epoch, batch_idx, total_batches, lossD, lossG, writerFake, writerReal, step):\n",
    "    print(f\"Epoch [{epoch}/{Config.numEpochs}], Batch [{batch_idx}/{total_batches}]\")\n",
    "    print(f\"Loss D: {lossD.item():.4f}, Loss G: {lossG.item():.4f}\")\n",
    "\n",
    "    # Log losses to TensorBoard\n",
    "    writerFake.add_scalar(\"Loss/Generator\", lossG.item(), step)\n",
    "    writerReal.add_scalar(\"Loss/Discriminator\", lossD.item(), step)\n",
    "\n",
    "    # Log fake and real images to TensorBoard\n",
    "    with torch.no_grad():\n",
    "        fake = gen(fixedNoise).view(-1, 1, 28, 28)\n",
    "        real = dataset.data[:16].view(-1, 1, 28, 28).float() / 127.5 - 1\n",
    "        writerFake.add_images(\"Generated Images\", fake, global_step=step)\n",
    "        writerReal.add_images(\"Real Images\", real, global_step=step)\n",
    "    \n",
    "    step += 1\n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a2d2e02-ccf4-47c8-ab16-1df281fbb24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Started Training and Visualization...\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [0/10], Batch [0/938]\n",
      "Loss D: 0.7123, Loss G: 0.6928\n",
      "Epoch [0/10], Batch [100/938]\n",
      "Loss D: 0.6377, Loss G: 0.6720\n",
      "Epoch [0/10], Batch [200/938]\n",
      "Loss D: 0.5380, Loss G: 0.8473\n",
      "Epoch [0/10], Batch [300/938]\n",
      "Loss D: 0.4199, Loss G: 1.0798\n",
      "Epoch [0/10], Batch [400/938]\n",
      "Loss D: 0.4273, Loss G: 1.2264\n",
      "Epoch [0/10], Batch [500/938]\n",
      "Loss D: 0.4869, Loss G: 0.9395\n",
      "Epoch [0/10], Batch [600/938]\n",
      "Loss D: 0.4767, Loss G: 1.0179\n",
      "Epoch [0/10], Batch [700/938]\n",
      "Loss D: 0.4893, Loss G: 0.9559\n",
      "Epoch [0/10], Batch [800/938]\n",
      "Loss D: 0.4754, Loss G: 1.1578\n",
      "Epoch [0/10], Batch [900/938]\n",
      "Loss D: 0.4990, Loss G: 1.1520\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [1/10], Batch [0/938]\n",
      "Loss D: 0.4957, Loss G: 1.1557\n",
      "Epoch [1/10], Batch [100/938]\n",
      "Loss D: 0.4688, Loss G: 1.1285\n",
      "Epoch [1/10], Batch [200/938]\n",
      "Loss D: 0.5035, Loss G: 0.8439\n",
      "Epoch [1/10], Batch [300/938]\n",
      "Loss D: 0.4362, Loss G: 0.8570\n",
      "Epoch [1/10], Batch [400/938]\n",
      "Loss D: 0.3727, Loss G: 1.3483\n",
      "Epoch [1/10], Batch [500/938]\n",
      "Loss D: 0.4393, Loss G: 1.6528\n",
      "Epoch [1/10], Batch [600/938]\n",
      "Loss D: 0.4148, Loss G: 1.4566\n",
      "Epoch [1/10], Batch [700/938]\n",
      "Loss D: 0.4547, Loss G: 1.0168\n",
      "Epoch [1/10], Batch [800/938]\n",
      "Loss D: 0.4467, Loss G: 1.5529\n",
      "Epoch [1/10], Batch [900/938]\n",
      "Loss D: 0.4278, Loss G: 1.1821\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [2/10], Batch [0/938]\n",
      "Loss D: 0.5094, Loss G: 1.7714\n",
      "Epoch [2/10], Batch [100/938]\n",
      "Loss D: 0.4408, Loss G: 1.0686\n",
      "Epoch [2/10], Batch [200/938]\n",
      "Loss D: 0.4217, Loss G: 1.1427\n",
      "Epoch [2/10], Batch [300/938]\n",
      "Loss D: 0.3980, Loss G: 1.0910\n",
      "Epoch [2/10], Batch [400/938]\n",
      "Loss D: 0.3470, Loss G: 1.8161\n",
      "Epoch [2/10], Batch [500/938]\n",
      "Loss D: 0.3904, Loss G: 1.7801\n",
      "Epoch [2/10], Batch [600/938]\n",
      "Loss D: 0.3803, Loss G: 1.5768\n",
      "Epoch [2/10], Batch [700/938]\n",
      "Loss D: 0.4829, Loss G: 0.9747\n",
      "Epoch [2/10], Batch [800/938]\n",
      "Loss D: 0.3644, Loss G: 1.4272\n",
      "Epoch [2/10], Batch [900/938]\n",
      "Loss D: 0.4522, Loss G: 1.7261\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [3/10], Batch [0/938]\n",
      "Loss D: 0.3813, Loss G: 1.2746\n",
      "Epoch [3/10], Batch [100/938]\n",
      "Loss D: 0.4269, Loss G: 1.2732\n",
      "Epoch [3/10], Batch [200/938]\n",
      "Loss D: 0.3522, Loss G: 1.9940\n",
      "Epoch [3/10], Batch [300/938]\n",
      "Loss D: 0.3683, Loss G: 1.3084\n",
      "Epoch [3/10], Batch [400/938]\n",
      "Loss D: 0.3606, Loss G: 1.9419\n",
      "Epoch [3/10], Batch [500/938]\n",
      "Loss D: 0.3924, Loss G: 1.8480\n",
      "Epoch [3/10], Batch [600/938]\n",
      "Loss D: 0.3657, Loss G: 1.2042\n",
      "Epoch [3/10], Batch [700/938]\n",
      "Loss D: 0.3697, Loss G: 1.6653\n",
      "Epoch [3/10], Batch [800/938]\n",
      "Loss D: 0.3556, Loss G: 1.8159\n",
      "Epoch [3/10], Batch [900/938]\n",
      "Loss D: 0.3877, Loss G: 2.0669\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [4/10], Batch [0/938]\n",
      "Loss D: 0.3662, Loss G: 1.8003\n",
      "Epoch [4/10], Batch [100/938]\n",
      "Loss D: 0.4080, Loss G: 1.7291\n",
      "Epoch [4/10], Batch [200/938]\n",
      "Loss D: 0.3530, Loss G: 1.1061\n",
      "Epoch [4/10], Batch [300/938]\n",
      "Loss D: 0.3206, Loss G: 2.1338\n",
      "Epoch [4/10], Batch [400/938]\n",
      "Loss D: 0.4288, Loss G: 1.1693\n",
      "Epoch [4/10], Batch [500/938]\n",
      "Loss D: 0.3131, Loss G: 1.5726\n",
      "Epoch [4/10], Batch [600/938]\n",
      "Loss D: 0.3895, Loss G: 0.9371\n",
      "Epoch [4/10], Batch [700/938]\n",
      "Loss D: 0.3626, Loss G: 1.2879\n",
      "Epoch [4/10], Batch [800/938]\n",
      "Loss D: 0.3293, Loss G: 1.5748\n",
      "Epoch [4/10], Batch [900/938]\n",
      "Loss D: 0.3215, Loss G: 1.8406\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [5/10], Batch [0/938]\n",
      "Loss D: 0.4145, Loss G: 2.0553\n",
      "Epoch [5/10], Batch [100/938]\n",
      "Loss D: 0.3129, Loss G: 1.4293\n",
      "Epoch [5/10], Batch [200/938]\n",
      "Loss D: 0.3121, Loss G: 1.3260\n",
      "Epoch [5/10], Batch [300/938]\n",
      "Loss D: 0.3031, Loss G: 1.6897\n",
      "Epoch [5/10], Batch [400/938]\n",
      "Loss D: 0.3801, Loss G: 2.2275\n",
      "Epoch [5/10], Batch [500/938]\n",
      "Loss D: 0.2953, Loss G: 1.5460\n",
      "Epoch [5/10], Batch [600/938]\n",
      "Loss D: 0.2826, Loss G: 1.8849\n",
      "Epoch [5/10], Batch [700/938]\n",
      "Loss D: 0.2972, Loss G: 2.4230\n",
      "Epoch [5/10], Batch [800/938]\n",
      "Loss D: 0.3260, Loss G: 2.6190\n",
      "Epoch [5/10], Batch [900/938]\n",
      "Loss D: 0.3529, Loss G: 1.7936\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [6/10], Batch [0/938]\n",
      "Loss D: 0.4957, Loss G: 0.8221\n",
      "Epoch [6/10], Batch [100/938]\n",
      "Loss D: 0.3023, Loss G: 2.0007\n",
      "Epoch [6/10], Batch [200/938]\n",
      "Loss D: 0.3225, Loss G: 1.9702\n",
      "Epoch [6/10], Batch [300/938]\n",
      "Loss D: 0.3168, Loss G: 1.4957\n",
      "Epoch [6/10], Batch [400/938]\n",
      "Loss D: 0.2123, Loss G: 2.3245\n",
      "Epoch [6/10], Batch [500/938]\n",
      "Loss D: 0.2618, Loss G: 2.4829\n",
      "Epoch [6/10], Batch [600/938]\n",
      "Loss D: 0.3517, Loss G: 1.2585\n",
      "Epoch [6/10], Batch [700/938]\n",
      "Loss D: 0.3370, Loss G: 2.2796\n",
      "Epoch [6/10], Batch [800/938]\n",
      "Loss D: 0.4096, Loss G: 1.6589\n",
      "Epoch [6/10], Batch [900/938]\n",
      "Loss D: 0.2415, Loss G: 2.0387\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [7/10], Batch [0/938]\n",
      "Loss D: 0.2710, Loss G: 2.8586\n",
      "Epoch [7/10], Batch [100/938]\n",
      "Loss D: 0.3185, Loss G: 2.7099\n",
      "Epoch [7/10], Batch [200/938]\n",
      "Loss D: 0.2745, Loss G: 2.2805\n",
      "Epoch [7/10], Batch [300/938]\n",
      "Loss D: 0.4130, Loss G: 2.3517\n",
      "Epoch [7/10], Batch [400/938]\n",
      "Loss D: 0.3060, Loss G: 1.6655\n",
      "Epoch [7/10], Batch [500/938]\n",
      "Loss D: 0.4024, Loss G: 1.3642\n",
      "Epoch [7/10], Batch [600/938]\n",
      "Loss D: 0.3719, Loss G: 1.6877\n",
      "Epoch [7/10], Batch [700/938]\n",
      "Loss D: 0.3095, Loss G: 1.9687\n",
      "Epoch [7/10], Batch [800/938]\n",
      "Loss D: 0.3726, Loss G: 2.6841\n",
      "Epoch [7/10], Batch [900/938]\n",
      "Loss D: 0.2536, Loss G: 2.5369\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [8/10], Batch [0/938]\n",
      "Loss D: 0.5120, Loss G: 2.5828\n",
      "Epoch [8/10], Batch [100/938]\n",
      "Loss D: 0.3248, Loss G: 1.9363\n",
      "Epoch [8/10], Batch [200/938]\n",
      "Loss D: 0.4018, Loss G: 1.2818\n",
      "Epoch [8/10], Batch [300/938]\n",
      "Loss D: 0.3352, Loss G: 1.9393\n",
      "Epoch [8/10], Batch [400/938]\n",
      "Loss D: 0.3771, Loss G: 1.2393\n",
      "Epoch [8/10], Batch [500/938]\n",
      "Loss D: 0.3481, Loss G: 1.5473\n",
      "Epoch [8/10], Batch [600/938]\n",
      "Loss D: 0.4361, Loss G: 1.1257\n",
      "Epoch [8/10], Batch [700/938]\n",
      "Loss D: 0.3108, Loss G: 2.2063\n",
      "Epoch [8/10], Batch [800/938]\n",
      "Loss D: 0.3217, Loss G: 1.6644\n",
      "Epoch [8/10], Batch [900/938]\n",
      "Loss D: 0.3035, Loss G: 1.7808\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [9/10], Batch [0/938]\n",
      "Loss D: 0.3530, Loss G: 1.3386\n",
      "Epoch [9/10], Batch [100/938]\n",
      "Loss D: 0.4245, Loss G: 1.5879\n",
      "Epoch [9/10], Batch [200/938]\n",
      "Loss D: 0.3633, Loss G: 2.5326\n",
      "Epoch [9/10], Batch [300/938]\n",
      "Loss D: 0.3203, Loss G: 2.0857\n",
      "Epoch [9/10], Batch [400/938]\n",
      "Loss D: 0.4057, Loss G: 2.6897\n",
      "Epoch [9/10], Batch [500/938]\n",
      "Loss D: 0.3867, Loss G: 1.3287\n",
      "Epoch [9/10], Batch [600/938]\n",
      "Loss D: 0.4924, Loss G: 1.2639\n",
      "Epoch [9/10], Batch [700/938]\n",
      "Loss D: 0.3967, Loss G: 2.3229\n",
      "Epoch [9/10], Batch [800/938]\n",
      "Loss D: 0.3126, Loss G: 1.9790\n",
      "Epoch [9/10], Batch [900/938]\n",
      "Loss D: 0.3164, Loss G: 2.2373\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training Loop\n",
    "step = 0\n",
    "print(\"\\nStarted Training and Visualization...\")\n",
    "for epoch in range(Config.numEpochs):\n",
    "    print('-' * 80)\n",
    "    for batch_idx, (real, _) in enumerate(loader):\n",
    "        real = real.view(-1, Config.imageDim).to(Config.device)\n",
    "        batchSize = real.size(0)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        noise = torch.randn(batchSize, Config.zDim).to(Config.device)\n",
    "        fake = gen(noise)\n",
    "        discReal = disc(real).view(-1)\n",
    "        discFake = disc(fake.detach()).view(-1)\n",
    "        \n",
    "        lossDreal = criterion(discReal, torch.ones_like(discReal))\n",
    "        lossDfake = criterion(discFake, torch.zeros_like(discFake))\n",
    "        lossD = (lossDreal + lossDfake) / 2\n",
    "\n",
    "        disc.zero_grad()\n",
    "        lossD.backward()\n",
    "        optDisc.step()\n",
    "\n",
    "        # Train Generator\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        optGen.step()\n",
    "\n",
    "        # Visualization and Logging\n",
    "        if batch_idx % Config.logStep == 0:\n",
    "            step = prepareVisualization(epoch, batch_idx, len(loader), lossD, lossG, writerFake, writerReal, step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59255d20-cfe0-4bd4-b1ed-d0c9592b382a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2a747c-80eb-4a01-aeee-ae9621410492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d80505-e7d7-47b7-a6cc-22679ecdc8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
