{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0dfac36-a684-4c13-9c3f-e3f0cbb73cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.baeldung.com/cs/pytorch-generative-adversarial-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce750d2-a73b-482a-80e3-df6a3d0aff6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "We train two competing and cooperating neural networks called generator (G ) and discriminator or critic (D). \n",
      "First, G takes random values from a multivariate Gaussian and produces a synthetic image. After that, \n",
      "D learns to distinguish between the real and the generated images. \n",
      "The goal of G is to produce a realistic sample that can fool D, whereas D has the opposite goal: \n",
      "to learn to differentiate actual from fake images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(''' \n",
    "We train two competing and cooperating neural networks called generator (G ) and discriminator or critic (D). \n",
    "First, G takes random values from a multivariate Gaussian and produces a synthetic image. After that, \n",
    "D learns to distinguish between the real and the generated images. \n",
    "The goal of G is to produce a realistic sample that can fool D, whereas D has the opposite goal: \n",
    "to learn to differentiate actual from fake images.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc7e5a3a-7ac9-4a3d-a25d-13e3e981d121",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 22:28:05.073504: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-01 22:28:05.083383: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733120885.094493   49632 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733120885.097884   49632 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-01 22:28:05.109682: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# For image transforms\n",
    "import torchvision.transforms as transforms\n",
    "# For Pytorch methods\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# For Optimizer\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "# For DATA SET\n",
    "from torchvision import datasets, transforms \n",
    "# FOR DATA LOADER\n",
    "from torch.utils.data import DataLoader\n",
    "# FOR TENSOR BOARD VISUALIZATION\n",
    "from torch.utils.tensorboard import SummaryWriter # to print to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b026a5cd-a2b6-4337-8b62-8aefe9222ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    zDim = 100            # Latent space dimension\n",
    "    imageDim = 28 * 28    # Flattened size of MNIST images\n",
    "    batchSize = 64        # Batch size\n",
    "    # numEpochs = 50      # Number of epochs\n",
    "    numEpochs = 10  \n",
    "    lr = 0.0002           # Learning rate\n",
    "    logStep = 100         # Logging frequency\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6630a0e7-73d6-4cab-8fd8-a585fd74c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "myTransforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,)),\n",
    "        ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a249fcd9-cc54-4b0d-bd5e-2f7d97554169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST is a handwritten digit database with each digit as a 28X28 monochrome images\n",
    "# Each image sample is flattened to a 784-dimensional vector (imageDim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e8d5b1e-b7e5-44ec-8436-06f5bf7e36dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(root=\"/home/bogdan/Desktop/PyTorch/MNIST/\",\n",
    "                         transform=myTransforms,\n",
    "                         download=True)\n",
    "loader = DataLoader(dataset,\n",
    "                    batch_size=Config.batchSize,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e61ae6ff-f9c8-460a-b6b1-b40ea650acf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We used a sequential neural network to implement the generator block. \n",
      "It comprises an input layer with the Leaky ReLu() activation function, \n",
      "followed by a single hidden layer with the tanh() activation function.\n"
     ]
    }
   ],
   "source": [
    "print('''We used a sequential neural network to implement the generator block. \n",
    "It comprises an input layer with the Leaky ReLu() activation function, \n",
    "followed by a single hidden layer with the tanh() activation function.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f6b3488-0932-4fd4-8165-52379f822d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, zDim, imgDim, hiddenDim=512, leakySlope=0.01):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(zDim, hiddenDim),\n",
    "            nn.LeakyReLU(leakySlope),\n",
    "            nn.Linear(hiddenDim, imgDim),\n",
    "            nn.Tanh(),  # Output normalized to [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee92370d-1d08-4ec0-a3b0-24b4d5163e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The discriminator network is similar to the generator. \n",
      "However, its output layer gives a single output \n",
      "(1 for real data and 0 for synthetic data)\n"
     ]
    }
   ],
   "source": [
    "print('''The discriminator network is similar to the generator. \n",
    "However, its output layer gives a single output \n",
    "(1 for real data and 0 for synthetic data)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cade2a0-f0cd-4bfb-b503-c62ad7e47ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, inFeatures, hiddenDim=512, leakySlope=0.01):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(inFeatures, hiddenDim),\n",
    "            nn.LeakyReLU(leakySlope),\n",
    "            nn.Linear(hiddenDim, 1),\n",
    "            nn.Sigmoid(),  # Output probability\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "391c8654-7f28-42ff-baa4-fdc645ae5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first create the generator and discriminator objects. \n",
    "# Then, we sample the standard Gaussian noise to generate random samples. \n",
    "# Following this step, we normalize the monochromatic image map (784-dimensional vector) \n",
    "# and convert it to a tensor for processing.\n",
    "\n",
    "# discriminator = Discriminator(Config.imageDim).to(Config.device)\n",
    "# generator = Generator(Config.zDim,\n",
    "#                       Config.imageDim).to(Config.device)\n",
    "\n",
    "# Fixed Noise\n",
    "fixedNoise = torch.randn((Config.batchSize,\n",
    "                              Config.zDim)).to(Config.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4963747-361c-4cc2-a491-c4ddde26211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the output image dimension is 28x28 = 784\n",
    "imgDim = 28 * 28  # Output image dimension for MNIST dataset\n",
    "# Model Initialization\n",
    "gen = Generator(Config.zDim, Config.imageDim).to(Config.device)\n",
    "disc = Discriminator(Config.imageDim).to(Config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e44cb2c-6489-464a-8748-8d21f20f5858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization operation reduces each channel’s pixel value with its mean and divides the result with its standard deviation:\n",
    "# image = image - mu / sigma\n",
    "# So, transforms.Normalize((0.5,), (0.5,)) converts MNIST image pixel values from the range [0, 1] to [-1, 1]. \n",
    "# Hence, this matches the tanh() output of G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c5a9259-5a17-4774-9372-53655c07b931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting Optimizers\n",
      "Setting the binary cross entropy (BCE) as loss function\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSetting Optimizers\")\n",
    "\n",
    "# Optimizers\n",
    "optGen = optim.Adam(gen.parameters(), lr=Config.lr, betas=(0.5, 0.999))\n",
    "optDisc = optim.Adam(disc.parameters(), lr=Config.lr, betas=(0.5, 0.999))\n",
    "\n",
    "print(f\"Setting the binary cross entropy (BCE) as loss function\")\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "245da5d0-61cc-4119-8a0a-8f04d607fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "writerFake = SummaryWriter(f\"logs/fake\")\n",
    "writerReal = SummaryWriter(f\"logs/real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2c1a633-1e71-441a-bd15-3cdef4355c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the training step: we get a random batch of real images from our dataset in each epoch. \n",
      "Then, we train our discriminator by showing it synthetic and real images. \n",
      "Once that’s over, we train the generator, keeping the discriminator intact. \n",
      "Finally, we come to the training step. We get a random batch of real images from our dataset in each epoch. \n",
      "Then, we train our discriminator by showing it synthetic and real images. \n",
      "Once that’s over, we train the generator, keeping the discriminator intact.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('''In the training step: we get a random batch of real images from our dataset in each epoch. \n",
    "Then, we train our discriminator by showing it synthetic and real images. \n",
    "Once that’s over, we train the generator, keeping the discriminator intact. \n",
    "Finally, we come to the training step. We get a random batch of real images from our dataset in each epoch. \n",
    "Then, we train our discriminator by showing it synthetic and real images. \n",
    "Once that’s over, we train the generator, keeping the discriminator intact.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bff7bbc-ec8f-4ec4-9368-84a4991786ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Function\n",
    "def prepareVisualization(epoch, batch_idx, total_batches, lossD, lossG, writerFake, writerReal, step):\n",
    "    print(f\"Epoch [{epoch}/{Config.numEpochs}], Batch [{batch_idx}/{total_batches}]\")\n",
    "    print(f\"Loss D: {lossD.item():.4f}, Loss G: {lossG.item():.4f}\")\n",
    "\n",
    "    # Log losses to TensorBoard\n",
    "    writerFake.add_scalar(\"Loss/Generator\", lossG.item(), step)\n",
    "    writerReal.add_scalar(\"Loss/Discriminator\", lossD.item(), step)\n",
    "\n",
    "    # Log fake and real images to TensorBoard\n",
    "    with torch.no_grad():\n",
    "        fake = gen(fixedNoise).view(-1, 1, 28, 28)\n",
    "        real = dataset.data[:16].view(-1, 1, 28, 28).float() / 127.5 - 1\n",
    "        writerFake.add_images(\"Generated Images\", fake, global_step=step)\n",
    "        writerReal.add_images(\"Real Images\", real, global_step=step)\n",
    "    \n",
    "    step += 1\n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a2d2e02-ccf4-47c8-ab16-1df281fbb24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Started Training and Visualization...\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [0/10], Batch [0/938]\n",
      "Loss D: 0.7123, Loss G: 0.6928\n",
      "Epoch [0/10], Batch [100/938]\n",
      "Loss D: 0.6377, Loss G: 0.6720\n",
      "Epoch [0/10], Batch [200/938]\n",
      "Loss D: 0.5380, Loss G: 0.8473\n",
      "Epoch [0/10], Batch [300/938]\n",
      "Loss D: 0.4199, Loss G: 1.0798\n",
      "Epoch [0/10], Batch [400/938]\n",
      "Loss D: 0.4273, Loss G: 1.2264\n",
      "Epoch [0/10], Batch [500/938]\n",
      "Loss D: 0.4869, Loss G: 0.9395\n",
      "Epoch [0/10], Batch [600/938]\n",
      "Loss D: 0.4767, Loss G: 1.0179\n",
      "Epoch [0/10], Batch [700/938]\n",
      "Loss D: 0.4893, Loss G: 0.9559\n",
      "Epoch [0/10], Batch [800/938]\n",
      "Loss D: 0.4754, Loss G: 1.1578\n",
      "Epoch [0/10], Batch [900/938]\n",
      "Loss D: 0.4990, Loss G: 1.1520\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [1/10], Batch [0/938]\n",
      "Loss D: 0.4957, Loss G: 1.1557\n",
      "Epoch [1/10], Batch [100/938]\n",
      "Loss D: 0.4688, Loss G: 1.1285\n",
      "Epoch [1/10], Batch [200/938]\n",
      "Loss D: 0.5035, Loss G: 0.8439\n",
      "Epoch [1/10], Batch [300/938]\n",
      "Loss D: 0.4362, Loss G: 0.8570\n",
      "Epoch [1/10], Batch [400/938]\n",
      "Loss D: 0.3727, Loss G: 1.3483\n",
      "Epoch [1/10], Batch [500/938]\n",
      "Loss D: 0.4393, Loss G: 1.6528\n",
      "Epoch [1/10], Batch [600/938]\n",
      "Loss D: 0.4148, Loss G: 1.4566\n",
      "Epoch [1/10], Batch [700/938]\n",
      "Loss D: 0.4547, Loss G: 1.0168\n",
      "Epoch [1/10], Batch [800/938]\n",
      "Loss D: 0.4467, Loss G: 1.5529\n",
      "Epoch [1/10], Batch [900/938]\n",
      "Loss D: 0.4278, Loss G: 1.1821\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [2/10], Batch [0/938]\n",
      "Loss D: 0.5094, Loss G: 1.7714\n",
      "Epoch [2/10], Batch [100/938]\n",
      "Loss D: 0.4408, Loss G: 1.0686\n",
      "Epoch [2/10], Batch [200/938]\n",
      "Loss D: 0.4217, Loss G: 1.1427\n",
      "Epoch [2/10], Batch [300/938]\n",
      "Loss D: 0.3980, Loss G: 1.0910\n",
      "Epoch [2/10], Batch [400/938]\n",
      "Loss D: 0.3470, Loss G: 1.8161\n",
      "Epoch [2/10], Batch [500/938]\n",
      "Loss D: 0.3904, Loss G: 1.7801\n",
      "Epoch [2/10], Batch [600/938]\n",
      "Loss D: 0.3803, Loss G: 1.5768\n",
      "Epoch [2/10], Batch [700/938]\n",
      "Loss D: 0.4829, Loss G: 0.9747\n",
      "Epoch [2/10], Batch [800/938]\n",
      "Loss D: 0.3644, Loss G: 1.4272\n",
      "Epoch [2/10], Batch [900/938]\n",
      "Loss D: 0.4522, Loss G: 1.7261\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [3/10], Batch [0/938]\n",
      "Loss D: 0.3813, Loss G: 1.2746\n",
      "Epoch [3/10], Batch [100/938]\n",
      "Loss D: 0.4269, Loss G: 1.2732\n",
      "Epoch [3/10], Batch [200/938]\n",
      "Loss D: 0.3522, Loss G: 1.9940\n",
      "Epoch [3/10], Batch [300/938]\n",
      "Loss D: 0.3683, Loss G: 1.3084\n",
      "Epoch [3/10], Batch [400/938]\n",
      "Loss D: 0.3606, Loss G: 1.9419\n",
      "Epoch [3/10], Batch [500/938]\n",
      "Loss D: 0.3924, Loss G: 1.8480\n",
      "Epoch [3/10], Batch [600/938]\n",
      "Loss D: 0.3657, Loss G: 1.2042\n",
      "Epoch [3/10], Batch [700/938]\n",
      "Loss D: 0.3697, Loss G: 1.6653\n",
      "Epoch [3/10], Batch [800/938]\n",
      "Loss D: 0.3556, Loss G: 1.8159\n",
      "Epoch [3/10], Batch [900/938]\n",
      "Loss D: 0.3877, Loss G: 2.0669\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [4/10], Batch [0/938]\n",
      "Loss D: 0.3662, Loss G: 1.8003\n",
      "Epoch [4/10], Batch [100/938]\n",
      "Loss D: 0.4080, Loss G: 1.7291\n",
      "Epoch [4/10], Batch [200/938]\n",
      "Loss D: 0.3530, Loss G: 1.1061\n",
      "Epoch [4/10], Batch [300/938]\n",
      "Loss D: 0.3206, Loss G: 2.1338\n",
      "Epoch [4/10], Batch [400/938]\n",
      "Loss D: 0.4288, Loss G: 1.1693\n",
      "Epoch [4/10], Batch [500/938]\n",
      "Loss D: 0.3131, Loss G: 1.5726\n",
      "Epoch [4/10], Batch [600/938]\n",
      "Loss D: 0.3895, Loss G: 0.9371\n",
      "Epoch [4/10], Batch [700/938]\n",
      "Loss D: 0.3626, Loss G: 1.2879\n",
      "Epoch [4/10], Batch [800/938]\n",
      "Loss D: 0.3293, Loss G: 1.5748\n",
      "Epoch [4/10], Batch [900/938]\n",
      "Loss D: 0.3215, Loss G: 1.8406\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [5/10], Batch [0/938]\n",
      "Loss D: 0.4145, Loss G: 2.0553\n",
      "Epoch [5/10], Batch [100/938]\n",
      "Loss D: 0.3129, Loss G: 1.4293\n",
      "Epoch [5/10], Batch [200/938]\n",
      "Loss D: 0.3121, Loss G: 1.3260\n",
      "Epoch [5/10], Batch [300/938]\n",
      "Loss D: 0.3031, Loss G: 1.6897\n",
      "Epoch [5/10], Batch [400/938]\n",
      "Loss D: 0.3801, Loss G: 2.2275\n",
      "Epoch [5/10], Batch [500/938]\n",
      "Loss D: 0.2953, Loss G: 1.5460\n",
      "Epoch [5/10], Batch [600/938]\n",
      "Loss D: 0.2826, Loss G: 1.8849\n",
      "Epoch [5/10], Batch [700/938]\n",
      "Loss D: 0.2972, Loss G: 2.4230\n",
      "Epoch [5/10], Batch [800/938]\n",
      "Loss D: 0.3260, Loss G: 2.6190\n",
      "Epoch [5/10], Batch [900/938]\n",
      "Loss D: 0.3529, Loss G: 1.7936\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [6/10], Batch [0/938]\n",
      "Loss D: 0.4957, Loss G: 0.8221\n",
      "Epoch [6/10], Batch [100/938]\n",
      "Loss D: 0.3023, Loss G: 2.0007\n",
      "Epoch [6/10], Batch [200/938]\n",
      "Loss D: 0.3225, Loss G: 1.9702\n",
      "Epoch [6/10], Batch [300/938]\n",
      "Loss D: 0.3168, Loss G: 1.4957\n",
      "Epoch [6/10], Batch [400/938]\n",
      "Loss D: 0.2123, Loss G: 2.3245\n",
      "Epoch [6/10], Batch [500/938]\n",
      "Loss D: 0.2618, Loss G: 2.4829\n",
      "Epoch [6/10], Batch [600/938]\n",
      "Loss D: 0.3517, Loss G: 1.2585\n",
      "Epoch [6/10], Batch [700/938]\n",
      "Loss D: 0.3370, Loss G: 2.2796\n",
      "Epoch [6/10], Batch [800/938]\n",
      "Loss D: 0.4096, Loss G: 1.6589\n",
      "Epoch [6/10], Batch [900/938]\n",
      "Loss D: 0.2415, Loss G: 2.0387\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [7/10], Batch [0/938]\n",
      "Loss D: 0.2710, Loss G: 2.8586\n",
      "Epoch [7/10], Batch [100/938]\n",
      "Loss D: 0.3185, Loss G: 2.7099\n",
      "Epoch [7/10], Batch [200/938]\n",
      "Loss D: 0.2745, Loss G: 2.2805\n",
      "Epoch [7/10], Batch [300/938]\n",
      "Loss D: 0.4130, Loss G: 2.3517\n",
      "Epoch [7/10], Batch [400/938]\n",
      "Loss D: 0.3060, Loss G: 1.6655\n",
      "Epoch [7/10], Batch [500/938]\n",
      "Loss D: 0.4024, Loss G: 1.3642\n",
      "Epoch [7/10], Batch [600/938]\n",
      "Loss D: 0.3719, Loss G: 1.6877\n",
      "Epoch [7/10], Batch [700/938]\n",
      "Loss D: 0.3095, Loss G: 1.9687\n",
      "Epoch [7/10], Batch [800/938]\n",
      "Loss D: 0.3726, Loss G: 2.6841\n",
      "Epoch [7/10], Batch [900/938]\n",
      "Loss D: 0.2536, Loss G: 2.5369\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [8/10], Batch [0/938]\n",
      "Loss D: 0.5120, Loss G: 2.5828\n",
      "Epoch [8/10], Batch [100/938]\n",
      "Loss D: 0.3248, Loss G: 1.9363\n",
      "Epoch [8/10], Batch [200/938]\n",
      "Loss D: 0.4018, Loss G: 1.2818\n",
      "Epoch [8/10], Batch [300/938]\n",
      "Loss D: 0.3352, Loss G: 1.9393\n",
      "Epoch [8/10], Batch [400/938]\n",
      "Loss D: 0.3771, Loss G: 1.2393\n",
      "Epoch [8/10], Batch [500/938]\n",
      "Loss D: 0.3481, Loss G: 1.5473\n",
      "Epoch [8/10], Batch [600/938]\n",
      "Loss D: 0.4361, Loss G: 1.1257\n",
      "Epoch [8/10], Batch [700/938]\n",
      "Loss D: 0.3108, Loss G: 2.2063\n",
      "Epoch [8/10], Batch [800/938]\n",
      "Loss D: 0.3217, Loss G: 1.6644\n",
      "Epoch [8/10], Batch [900/938]\n",
      "Loss D: 0.3035, Loss G: 1.7808\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch [9/10], Batch [0/938]\n",
      "Loss D: 0.3530, Loss G: 1.3386\n",
      "Epoch [9/10], Batch [100/938]\n",
      "Loss D: 0.4245, Loss G: 1.5879\n",
      "Epoch [9/10], Batch [200/938]\n",
      "Loss D: 0.3633, Loss G: 2.5326\n",
      "Epoch [9/10], Batch [300/938]\n",
      "Loss D: 0.3203, Loss G: 2.0857\n",
      "Epoch [9/10], Batch [400/938]\n",
      "Loss D: 0.4057, Loss G: 2.6897\n",
      "Epoch [9/10], Batch [500/938]\n",
      "Loss D: 0.3867, Loss G: 1.3287\n",
      "Epoch [9/10], Batch [600/938]\n",
      "Loss D: 0.4924, Loss G: 1.2639\n",
      "Epoch [9/10], Batch [700/938]\n",
      "Loss D: 0.3967, Loss G: 2.3229\n",
      "Epoch [9/10], Batch [800/938]\n",
      "Loss D: 0.3126, Loss G: 1.9790\n",
      "Epoch [9/10], Batch [900/938]\n",
      "Loss D: 0.3164, Loss G: 2.2373\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training Loop\n",
    "step = 0\n",
    "print(\"\\nStarted Training and Visualization...\")\n",
    "for epoch in range(Config.numEpochs):\n",
    "    print('-' * 80)\n",
    "    for batch_idx, (real, _) in enumerate(loader):\n",
    "        real = real.view(-1, Config.imageDim).to(Config.device)\n",
    "        batchSize = real.size(0)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        noise = torch.randn(batchSize, Config.zDim).to(Config.device)\n",
    "        fake = gen(noise)\n",
    "        discReal = disc(real).view(-1)\n",
    "        discFake = disc(fake.detach()).view(-1)\n",
    "        \n",
    "        lossDreal = criterion(discReal, torch.ones_like(discReal))\n",
    "        lossDfake = criterion(discFake, torch.zeros_like(discFake))\n",
    "        lossD = (lossDreal + lossDfake) / 2\n",
    "\n",
    "        disc.zero_grad()\n",
    "        lossD.backward()\n",
    "        optDisc.step()\n",
    "\n",
    "        # Train Generator\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        optGen.step()\n",
    "\n",
    "        # Visualization and Logging\n",
    "        if batch_idx % Config.logStep == 0:\n",
    "            step = prepareVisualization(epoch, batch_idx, len(loader), lossD, lossG, writerFake, writerReal, step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59255d20-cfe0-4bd4-b1ed-d0c9592b382a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2a747c-80eb-4a01-aeee-ae9621410492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d80505-e7d7-47b7-a6cc-22679ecdc8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
